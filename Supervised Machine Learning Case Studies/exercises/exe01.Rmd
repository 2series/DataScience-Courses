---
title: 'Case Study #1'
author: "RIHAD VARIAWA, Data Scientist"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
    keep_md: yes
    theme: spacelab
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, comment = "")
```


```{r analysis_setup, message = FALSE, warning = FALSE}
library(data.table, quietly = TRUE, warn.conflicts = FALSE)

assignInNamespace("cedta.pkgEvalsUserCode", c(data.table:::cedta.pkgEvalsUserCode, "rtvs"), "data.table")

library(tidyverse, quietly = TRUE, warn.conflicts = FALSE)
library(caret, quietly = TRUE, warn.conflicts = FALSE)
library(randomForest, quietly = TRUE, warn.conflicts = FALSE)
library(yardstick, quietly = TRUE, warn.conflicts = FALSE)
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)
library(ggplot2, quietly = TRUE, warn.conflicts = FALSE)
library(ggthemes, quietly = TRUE, warn.conflicts = FALSE)
library(gridExtra, quietly = TRUE, warn.conflicts = FALSE)
library(kableExtra, quietly = TRUE, warn.conflicts = FALSE)
library(GGally, quietly = TRUE, warn.conflicts = FALSE)
library(knitr, quietly = TRUE, warn.conflicts = FALSE)
library(RColorBrewer, quietly = TRUE, warn.conflicts = FALSE)
library(moments, quietly = TRUE, warn.conflicts = FALSE)

theme_set(theme_light())

# Theme Overrides
theme_update(plot.title = element_text(hjust = 0.5),
             axis.text.x = element_text(size = 10),
             axis.text.y = element_text(size = 10),
             axis.title = element_text(face = "bold", size = 12, colour = "steelblue4"),
             legend.position = "top", legend.title = element_blank())

data.path <- paste0(base.dir, "/cloud/project/suoervised-ML-case-studies-course/")

```


```{r}
# <exercise id="3" title="Visualizing the fuel efficiency distribution">
#   
#   The first step before you start modeling is to explore your data. In this course we'll
#   practice using tidyverse functions for exploratory data analysis. Start off this case study 
#   by examing your dataset and visualizing the distribution of fuel efficiency. 
#   The ggplot2 package, with functions like 
#   [`ggplot()`](https://ggplot2.tidyverse.org/reference/ggplot.html) and 
#   [`geom_histogram()`](https://ggplot2.tidyverse.org/reference/geom_histogram.html) 
#   are included in the tidyverse.
# 
# 
# **Instructions**
#   
#   The first time you run a code exercise, it may take a little while for your 
#   Docker container on [mybinder.org](https://mybinder.org/v2/gh/juliasilge/supervised-ML-case-studies-course/binder)
#   to load. ‚è≥ Try to be patient!
#   
#   **Wherever you see `___` in a code exercise, replace it with the correct code as instructed.
#     Run the code (via the button) to see if it will run, and submit it (via the other button)
#     to check if it's correct.**
# 
# `tidyverse` is loaded for you. 
# 
# - Print the `cars2018` object. Notice that some of the column names have spaces in them and
#   are surrounded by backticks, like `` `Recommended Fuel` ``.
# - Use the appropriate column from the dataset in the call to `aes()` so you can plot 
#   a histogram of fuel efficiency (MPG).
# - Set the correct `x` and `y` labels.
# 
# <codeblock id="01_03">
# 
# - The column `MPG` contains the fuel efficiency measurements so to make the plot, 
#   call `aes(x = MPG)`.
# - The number of cars goes on the y-axis and the fuel efficiency goes on the x-axis.
# 
# </codeblock>
# 
# </exercise>



# library(tidyverse)
cars2018 <- read_csv("data/cars2018.csv")

# Print the cars2018 object
glimpse(cars2018)

# Plot the histogram
ggplot(cars2018, aes(x = MPG)) +
    geom_histogram(bins = 25) +
    labs(x = "Fuel efficiency (mpg)",
         y = "Number of cars")
```


```{r}
# <exercise id="4" title="Building a simple linear model">
#   
#   Before embarking on more complex machine learning models, it's a good idea to 
#   build the simplest possible model to get an idea of what is going on. 
#   In this case, that means fitting a simple linear model using base R's `lm()` function.
# 
# **Instructions**
#   
#   - Use [`select()`](https://dplyr.tidyverse.org/reference/select.html) to deselect 
#     the two columns `Model` and `Model Index` from the model; these columns tell us the 
#     individual identifiers for each car and it would *not* make sense to include them in 
#     modeling. 
#   - Fit `MPG` as the predicted quantity, explained by all the predictors, 
#     i.e., `.` in the R formula input to `lm()`. (You may have noticed the log distribution
#     of MPG in the last exercise, but don't worry about fitting the logarithm of fuel 
#     efficiency yet.) 
#   - Print the summary of the model.


# library(tidyverse)
cars2018 <- read_csv("data/cars2018.csv")

# Deselect the 2 columns to create cars_vars
car_vars <- cars2018 %>%
    select(-Model, -`Model Index`)

# Fit a linear model
fit_all <- lm(MPG ~ ., data = car_vars)

# Print the summary of the model
summary(fit_all)
```


```{r}
# <exercise id="6" title="Training and testing data">
#   
#   Training models based on all of your data at once is typically not the best choice. üö´ 
#   Instead, you can create subsets of your data that you use for different purposes, 
#   such as *training* your model and then *testing* your model. 
# 
# Creating training/testing splits reduces overfitting. 
# When you evaluate your model on data that it was not trained on, 
# you get a better estimate of how it will perform on new data.
# 
# **Instructions**
#   
#   - Load the `rsample` package. 
#   - Create a data split that divides the original data into 80%/20% sections and
#     (roughly) evenly divides the partitions between the different types of `Transmission`.
#   - Assign the 80% partition to `car_train` and the 20% partition to `car_test`.
#   - To load a package in R, use `library(package_name)`.
#   - `initial_split()` takes as its arguments, after the data that you pipe in: `prop`, 
#     the proportion of data to include in the training set, and then `strata`, the variable 
#     to partition evenly across.
#   - Once you create the `car_split` object, you can use it to determine your training set 
#     and testing set.


# library(tidyverse)
car_vars <- readRDS("data/c1_cars_vars_full.rds")

# Load rsample
library(rsample)

# Split the data into training and test sets
set.seed(1234)
car_split <- car_vars %>%
    initial_split(prop = 0.8, strata = "Transmission")

car_train <- training(car_split)
car_test <- testing(car_split)
```

```{r}
# <exercise id="7" title="Training models with caret">
#   
#   Now that your `car_train` data is ready, you can fit a set of models with caret. 
#   The [`train()`](https://topepo.github.io/caret/model-training-and-tuning.html#model-training-and-parameter-tuning)
#   function from caret is flexible and powerful. It allows you to try out many different kinds of models and 
#   fitting procedures. To start off, train one linear regression model and one random forest model, without 
#   any resampling. (This is what `trainControl(method = "none")` does; it turns off all resampling.)
#                                                                                                    
# **Instructions**
#                                                                                                      
#   - Load the caret package. 
#   - Train a basic linear regression model on your `car_train` data. 
#                                                                                                    
# (Notice that we are fitting to `log(MPG)` since the fuel efficiency (mpg) had a log normal distribution.)
#                                                                                                    
# <codeblock id="01_07_1">
#                                                                                                      
# For linear regression, use `method = "lm"`.
#                                                                                                    
# </codeblock>
#                                                                                                      
# **Instructions**
#                                                                                                      
#   - Train a random forest model on your `car_train` data.
                                                                                                   

# library(tidyverse)

car_train <- readRDS("data/c1_training_full.rds")
car_test <- readRDS("data/c1_testing_full.rds")

# Load caret
library(caret)

# Train a linear regression model
fit_lm <- train(log(MPG) ~ ., 
                method = "lm", 
                data = car_train,
                trControl = trainControl(method = "none"))

# Print the model object
fit_lm
```


```{r}
# <exercise id="7" title="Training models with caret">
#   
#   Now that your `car_train` data is ready, you can fit a set of models with caret. 
#   The [`train()`](https://topepo.github.io/caret/model-training-and-tuning.html#model-training-and-parameter-tuning)
#   function from caret is flexible and powerful. It allows you to try out many different kinds of models and 
#   fitting procedures. To start off, train one linear regression model and one random forest model, without 
#   any resampling. (This is what `trainControl(method = "none")` does; it turns off all resampling.)
#                                                                                                    
# **Instructions**
#                                                                                                      
#   - Load the caret package. 
#   - Train a basic linear regression model on your `car_train` data. 
#                                                                                                    
# (Notice that we are fitting to `log(MPG)` since the fuel efficiency (mpg) had a log normal distribution.)
#                                                                                                    
# <codeblock id="01_07_1">
#                                                                                                      
# For linear regression, use `method = "lm"`.
#                                                                                                    
# </codeblock>
#                                                                                                      
# **Instructions**
#                                                                                                      
#   - Train a random forest model on your `car_train` data.

# <codeblock id="01_07_2">
#   
#   For random forest, use `method = "rf"`.
# 
# </codeblock>
#   
#   </exercise>
  



# library(tidyverse)
# library(caret)
# library(randomForest)

car_train <- readRDS("data/c1_training_full.rds")
car_test <- readRDS("data/c1_testing_full.rds")

# Train a random forest model
fit_rf <- train(log(MPG) ~ ., 
                method = "rf", 
                data = car_train,
                trControl = trainControl(method = "none"))

# Print the model object
fit_rf

```


```{r}
# <exercise id="8" title="Evaluating your models">
#   
#   The `fit_lm` and `fit_rf` models you just trained are in your environment. It's time to evaluate them!
#   ü§© For regression models, we will focus on evaluating using the **root mean squared error**. This quantity
#   is measured in the same units as the original data (log of miles per gallon, in our case). Lower values 
#   indicate a better fit to the data. It's not too hard to calculate root mean squared error manually, but 
#   the [yardstick](https://tidymodels.github.io/yardstick/) package offers convenient functions for 
#   this and other model performance metrics.
# 
# **Instructions**
#   
#   - Load the yardstick package. 
#   - Create new columns for model predictions from each of the models you have trained, first linear regression
#     and then random forest.
#   - Evaluate the performance of these models using 
#     [`metrics()`](https://tidymodels.github.io/yardstick/reference/metrics.html) by specifying the column 
#     in the original data that contains the real fuel efficiency.
# 
# <codeblock id="01_08">
#   
#   - Use `fit_lm` to predict the values for linear regression and `fit_rf` to predict values for random forest.
#   - The "truth" column in the original data is the column that holds fuel efficiency, `MPG`.
# 
# </codeblock>
#   
#   </exercise>



# library(caret)
# library(tidyverse)

car_train <- readRDS("data/c1_training_full.rds")
fit_lm <- readRDS("data/c1_fit_lm.rds")
fit_rf <- readRDS("data/c1_fit_rf.rds")

# Load yardstick
library(yardstick)

# Create the new columns
results <- car_train %>%
    mutate(MPG = log(MPG),
           `Linear regression` = predict(fit_lm, car_train),
           `Random forest` = predict(fit_rf, car_train))

# Evaluate the performance
metrics(results, truth = MPG, estimate = `Linear regression`)
metrics(results, truth = MPG, estimate = `Random forest`)

```

```{r}
# <exercise id="9" title="Using the testing data">
#   
#   "But wait!" you say, because you have been paying attention. ü§î "That is how these models perform on
#    the *training* data, the data that we used to build these models in the first place." Let's evaluate 
#    how these simple models perform on the testing data.
# 
# **Instructions**
# 
# What do you need to change to evaluate how the models perform on the testing data, instead of 
# the training data?
# 
# <codeblock id="01_09">
# 
# Where you had `car_train` before, switch out to `car_test`.
# 
# </codeblock>
# 
# </exercise>



# library(caret)
# library(tidyverse)
# library(yardstick)

car_test <- readRDS("data/c1_testing_full.rds")
fit_lm <- readRDS("data/c1_fit_lm.rds")
fit_rf <- readRDS("data/c1_fit_rf.rds")

# Create the new columns
results <- car_test %>%
    mutate(MPG = log(MPG),
           `Linear regression` = predict(fit_lm, car_test),
           `Random forest` = predict(fit_rf, car_test))

# Evaluate the performance
metrics(results, truth = MPG, estimate = `Linear regression`)
metrics(results, truth = MPG, estimate = `Random forest`)


```


```{r}
# <exercise id="11" title="Bootstrap resampling">
#   
#   In the last set of exercises, you trained linear regression and random forest models without
#   any resampling. Resampling can improve the accuracy of machine learning models, and reduce overfitting.
# 
# Let's try bootstrap resampling, which means creating datasets the same size as the original one by
# randomly drawing with replacement from the original. In caret, the default behavior for bootstrapping
# is 25 resamplings, but you can change this using 
# [`trainControl()`](https://topepo.github.io/caret/model-training-and-tuning.html#tune) if desired.
# 
# **Instructions**
# 
# The datasets available in your environment are 10% of their original size, to allow the code
# in this exercise to evaluate quickly. (This means you may see some warnings, such as about 
# rank-deficient fits.)
# 
# - Which dataset should you train these models with, `car_train` or `car_test`?
# - Train these models using bootstrap resampling. The method for this is `"boot"`.
# 
# <codeblock id="01_11">
# 
# You should still use the training data, `car_train`, for training these models.
# 
# </codeblock>
# 
# </exercise>



# library(caret)
# library(tidyverse)

car_train <- readRDS("data/c1_training_one_percent.rds")

# Fit the models with bootstrap resampling
cars_lm_bt <- train(log(MPG) ~ ., 
                    method = "lm", 
                    data = car_train,
                    trControl = trainControl(method = "boot"))

cars_rf_bt <- train(log(MPG) ~ ., 
                    method = "rf", 
                    data = car_train,
                    trControl = trainControl(method = "boot"))
                   
# Quick look at the models
cars_lm_bt
cars_rf_bt

```


```{r}
# <exercise id="12" title="Plotting modeling results">
#   
#   You just trained models using bootstrap resampling, `cars_lm_bt` and `cars_rf_bt`. 
#   These models are available in your environment, trained on the entire training set 
#   instead of 10% only. Now let's evaluate how those models performed and compare them. 
#   We will again use `metrics()` from the yardstick package, but also we will plot the 
#   model predictions to inspect them visually.
# 
# Notice in this code how we use 
# [`gather()`](https://tidyr.tidyverse.org/reference/gather.html) from tidyr 
# (another tidyverse package) to tidy the dataframe and prepare it for plotting with ggplot2.
# 
# **Instructions**
# 
# - Use [`mutate()`](https://dplyr.tidyverse.org/reference/mutate.html) to create the new columns
#   with the predictions from the two models you trained.
# - Choose which columns should be specified as `truth` and which should be `estimate` when calling
#   `metrics()`.
# 
# <codeblock id="01_12_1">
# 
# Specify the `MPG` column as `truth` and the column created from the prediction (either `Linear regression` or `Random forest`) as `estimate`.
# 
# </codeblock>




# library(caret)
# library(tidyverse)
# library(yardstick)

car_test <- readRDS("data/c1_testing_full.rds")
cars_lm_bt <- readRDS("data/cars_lm_bt.rds")
cars_rf_bt <- readRDS("data/cars_rf_bt.rds")

results <- car_test %>%
    mutate(MPG = log(MPG),
        `Linear regression` = predict(cars_lm_bt, car_test),
           `Random forest` = predict(cars_rf_bt, car_test))

metrics(results, truth = MPG, estimate = `Linear regression`)
metrics(results, truth = MPG, estimate = `Random forest`)

```

```{r}
# <exercise id="12" title="Plotting modeling results">
#   
#   You just trained models using bootstrap resampling, `cars_lm_bt` and `cars_rf_bt`. 
#   These models are available in your environment, trained on the entire training set 
#   instead of 10% only. Now let's evaluate how those models performed and compare them. 
#   We will again use `metrics()` from the yardstick package, but also we will plot the 
#   model predictions to inspect them visually.
# 
# Notice in this code how we use 
# [`gather()`](https://tidyr.tidyverse.org/reference/gather.html) from tidyr 
# (another tidyverse package) to tidy the dataframe and prepare it for plotting with ggplot2.
# 
# **Instructions**
# 
# - Use [`mutate()`](https://dplyr.tidyverse.org/reference/mutate.html) to create the new columns
#   with the predictions from the two models you trained.
# - Choose which columns should be specified as `truth` and which should be `estimate` when calling
#   `metrics()`.
# 
# <codeblock id="01_12_1">
# 
# Specify the `MPG` column as `truth` and the column created from the prediction (either `Linear regression` or `Random forest`) as `estimate`.
# 
# </codeblock>


# **Instructions**
#     
# Wonderful! Sit back and run the given code to visualize the results!
#     
# <codeblock id="01_12_2">
#         
#   You just need to run the code given to you.
#     
# </codeblock>
#         
#  </exercise>
        

# library(caret)
# library(tidyverse)
# library(yardstick)

car_test <- readRDS("data/c1_testing_full.rds")
cars_lm_bt <- readRDS("data/cars_lm_bt.rds")
cars_rf_bt <- readRDS("data/cars_rf_bt.rds")

results <- car_test %>%
    mutate(MPG = log(MPG),
           `Linear regression` = predict(cars_lm_bt, car_test),
           `Random forest` = predict(cars_rf_bt, car_test))

results %>%
    gather(Method, Result, `Linear regression`:`Random forest`) %>%
    ggplot(aes(MPG, Result, color = Method)) +
    geom_point(size = 1.5, alpha = 0.5) +
    facet_wrap(~Method) +
    geom_abline(lty = 2, color = "gray50") +
    geom_smooth(method = "lm")


```

