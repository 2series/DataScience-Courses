{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics from Stock Data\n",
    "\n",
    "In this lab we will load stock data into a Pandas Dataframe and calculate some statistics on it. We will be working with stock data from Google, Apple, and Amazon. All the stock data was downloaded from yahoo finance in CSV format. In your workspace you should have a file named GOOG.csv containing the Google stock data, a file named AAPL.csv containing the Apple stock data, and a file  named AMZN.csv containing the Amazon stock data. (You can see the workspace folder by clicking on the Jupyter logo in the upper left corner of the workspace.) All the files contain 7 columns of data:\n",
    "\n",
    "**Date Open High Low Close Adj_Close Volume**\n",
    "\n",
    "We will start by reading in any of the above CSV files into a DataFrame and see what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-08-19</td>\n",
       "      <td>49.676899</td>\n",
       "      <td>51.693783</td>\n",
       "      <td>47.669952</td>\n",
       "      <td>49.845802</td>\n",
       "      <td>49.845802</td>\n",
       "      <td>44994500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-08-20</td>\n",
       "      <td>50.178635</td>\n",
       "      <td>54.187561</td>\n",
       "      <td>49.925285</td>\n",
       "      <td>53.805050</td>\n",
       "      <td>53.805050</td>\n",
       "      <td>23005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-08-23</td>\n",
       "      <td>55.017166</td>\n",
       "      <td>56.373344</td>\n",
       "      <td>54.172661</td>\n",
       "      <td>54.346527</td>\n",
       "      <td>54.346527</td>\n",
       "      <td>18393200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-08-24</td>\n",
       "      <td>55.260582</td>\n",
       "      <td>55.439419</td>\n",
       "      <td>51.450363</td>\n",
       "      <td>52.096165</td>\n",
       "      <td>52.096165</td>\n",
       "      <td>15361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-08-25</td>\n",
       "      <td>52.140873</td>\n",
       "      <td>53.651051</td>\n",
       "      <td>51.604362</td>\n",
       "      <td>52.657513</td>\n",
       "      <td>52.657513</td>\n",
       "      <td>9257400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2004-08-19  49.676899  51.693783  47.669952  49.845802  49.845802  44994500\n",
       "1  2004-08-20  50.178635  54.187561  49.925285  53.805050  53.805050  23005800\n",
       "2  2004-08-23  55.017166  56.373344  54.172661  54.346527  54.346527  18393200\n",
       "3  2004-08-24  55.260582  55.439419  51.450363  52.096165  52.096165  15361800\n",
       "4  2004-08-25  52.140873  53.651051  51.604362  52.657513  52.657513   9257400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We import pandas into Python\n",
    "import pandas as pd\n",
    "\n",
    "# We read in a stock data data file into a data frame and see what it looks like\n",
    "df = pd.read_csv('./GOOG.csv')\n",
    "\n",
    "# We display the first 5 rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that the Dataframe is has automatically labeled the row indices using integers and has labeled the columns of the DataFrame using the names of the columns in the CSV files.\n",
    "\n",
    "# To Do\n",
    "\n",
    "You will now load the stock data from Google, Apple, and Amazon into separte DataFrames. However, for each stock data you will only be interested in loading the `Date` and `Adj Close` columns into the Dataframe. In addtion, you want to use the `Date` column as your row index. Finally, you want the DataFrame to recognize the dates as actual dates (year/month/day) and not as strings. For each stock, you can accomplish all theses things in just one line of code by using the appropiate keywords in the `pd.read_csv()` function. Here are a few hints:\n",
    "\n",
    "* Use the `index_col` keyword to indicate which column you want to use as an index. For example `index_col = ['Open']`\n",
    "\n",
    "* Set the `parse_dates` keyword equal to `True` to convert the Dates into real dates of the form year/month/day\n",
    "\n",
    "* Use the `usecols` keyword to select which columns you want to load into the DataFrame. For example `usecols = ['Open', 'High']`\n",
    "\n",
    "Fill in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the Google stock data into a DataFrame\n",
    "google_stock = pd.read_csv('./GOOG.csv',index_col=['Date'], parse_dates=True,usecols=['Date','Adj Close'])\n",
    "\n",
    "# We load the Apple stock data into a DataFrame\n",
    "apple_stock = pd.read_csv('./AAPL.csv',index_col=['Date'], parse_dates=True,usecols=['Date','Adj Close'])\n",
    "\n",
    "# We load the Amazon stock data into a DataFrame\n",
    "amazon_stock = pd.read_csv('./AMZN.csv',index_col=['Date'], parse_dates=True,usecols=['Date','Adj Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that you have loaded the data correctly by displaying the head of the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-19</th>\n",
       "      <td>49.845802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-20</th>\n",
       "      <td>53.805050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-23</th>\n",
       "      <td>54.346527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-24</th>\n",
       "      <td>52.096165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-25</th>\n",
       "      <td>52.657513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2004-08-19  49.845802\n",
       "2004-08-20  53.805050\n",
       "2004-08-23  54.346527\n",
       "2004-08-24  52.096165\n",
       "2004-08-25  52.657513"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We display the google_stock DataFrame\n",
    "google_stock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now join the three DataFrames above to create a single new DataFrame that contains all the `Adj Close` for all the stocks. Let's start by creating an empty DataFrame that has as row indices calendar days between `2000-01-01`  and `2016-12-31`. We will use the `pd.date_range()` function to create the calendar dates first and then we will create a DataFrame that uses those dates as row indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Adj Close\n",
      "Date                  \n",
      "2004-08-19   49.845802\n",
      "2004-08-20   53.805050\n",
      "2004-08-23   54.346527\n",
      "2004-08-24   52.096165\n",
      "2004-08-25   52.657513\n",
      "2004-08-26   53.606342\n",
      "2004-08-27   52.732029\n",
      "2004-08-30   50.675404\n",
      "2004-08-31   50.854240\n",
      "2004-09-01   49.801090\n",
      "2004-09-02   50.427021\n",
      "2004-09-03   49.681866\n",
      "2004-09-07   50.461796\n",
      "2004-09-08   50.819469\n",
      "2004-09-09   50.824436\n",
      "2004-09-10   52.324677\n",
      "2004-09-13   53.402668\n",
      "2004-09-14   55.384777\n",
      "2004-09-15   55.638126\n",
      "2004-09-16   56.616764\n",
      "2004-09-17   58.365391\n",
      "2004-09-20   59.294346\n",
      "2004-09-21   58.539257\n",
      "2004-09-22   58.807514\n",
      "2004-09-23   60.019630\n",
      "2004-09-24   59.527828\n",
      "2004-09-27   58.747902\n",
      "2004-09-28   63.020115\n",
      "2004-09-29   65.116478\n",
      "2004-09-30   64.381264\n",
      "...                ...\n",
      "2017-09-01  937.340027\n",
      "2017-09-05  928.450012\n",
      "2017-09-06  927.809998\n",
      "2017-09-07  935.950012\n",
      "2017-09-08  926.500000\n",
      "2017-09-11  929.080017\n",
      "2017-09-12  932.070007\n",
      "2017-09-13  935.090027\n",
      "2017-09-14  925.109985\n",
      "2017-09-15  920.289978\n",
      "2017-09-18  915.000000\n",
      "2017-09-19  921.809998\n",
      "2017-09-20  931.580017\n",
      "2017-09-21  932.450012\n",
      "2017-09-22  928.530029\n",
      "2017-09-25  920.969971\n",
      "2017-09-26  924.859985\n",
      "2017-09-27  944.489990\n",
      "2017-09-28  949.500000\n",
      "2017-09-29  959.109985\n",
      "2017-10-02  953.270020\n",
      "2017-10-03  957.789978\n",
      "2017-10-04  951.679993\n",
      "2017-10-05  969.960022\n",
      "2017-10-06  978.890015\n",
      "2017-10-09  977.000000\n",
      "2017-10-10  972.599976\n",
      "2017-10-11  989.250000\n",
      "2017-10-12  987.830017\n",
      "2017-10-13  989.679993\n",
      "\n",
      "[3313 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# We create calendar dates between '2000-01-01' and  '2016-12-31'\n",
    "dates = pd.date_range('2000-01-01', '2016-12-31')\n",
    "\n",
    "# We create and empty DataFrame that uses the above dates as indices\n",
    "all_stocks = pd.DataFrame(index = dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "You will now join the the individual DataFrames, `google_stock`, `apple_stock`, and `amazon_stock`, to the `all_stocks` DataFrame. However, before you do this, it is necessary that you change the name of the columns in each of the three dataframes. This is because the column labels in the `all_stocks` dataframe must be unique. Since all the columns in the individual dataframes have the same name, `Adj Close`, we must change them to the stock name before joining them. In the space below change the column label `Adj Close` of each individual dataframe to the name of the corresponding stock. You can do this by using the `pd.DataFrame.rename()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Adj Close column label to Google\n",
    "google_stock = google_stock.rename(columns={'Adj Close':'Google'}) \n",
    "\n",
    "# Change the Adj Close column label to Apple\n",
    "apple_stock = apple_stock.rename(columns={'Adj Close':'AAPL'}) \n",
    "\n",
    "# Change the Adj Close column label to Amazon\n",
    "amazon_stock = amazon_stock.rename(columns={'Adj Close':'AMZN'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the column labels have been changed correctly by displaying the datadrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOOG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-19</th>\n",
       "      <td>49.845802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-20</th>\n",
       "      <td>53.805050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-23</th>\n",
       "      <td>54.346527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-24</th>\n",
       "      <td>52.096165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-25</th>\n",
       "      <td>52.657513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GOOG\n",
       "Date                 \n",
       "2004-08-19  49.845802\n",
       "2004-08-20  53.805050\n",
       "2004-08-23  54.346527\n",
       "2004-08-24  52.096165\n",
       "2004-08-25  52.657513"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We display the google_stock DataFrame\n",
    "google_stock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have unique column labels, we can join the individual DataFrames to the `all_stocks` DataFrame. For this we will use the `dataframe.join()` function. The function `dataframe1.join(dataframe2)` joins `dataframe1` with `dataframe2`. We will join each dataframe one by one to the `all_stocks` dataframe. Fill in the code below to join the dataframes, the first join has been made for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We join the Google stock to all_stocks\n",
    "all_stocks = all_stocks.join(google_stock)\n",
    "\n",
    "# We join the Apple stock to all_stocks\n",
    "all_stocks = all_stocks.join(apple_stock)\n",
    "\n",
    "# We join the Amazon stock to all_stocks\n",
    "all_stocks = all_stocks.join(amazon_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that the dataframes have been joined correctly by displaying the `all_stocks`  dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOOG</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.596616</td>\n",
       "      <td>89.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.293384</td>\n",
       "      <td>81.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.341579</td>\n",
       "      <td>69.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GOOG      AAPL     AMZN\n",
       "2000-01-01   NaN       NaN      NaN\n",
       "2000-01-02   NaN       NaN      NaN\n",
       "2000-01-03   NaN  3.596616  89.3750\n",
       "2000-01-04   NaN  3.293384  81.9375\n",
       "2000-01-05   NaN  3.341579  69.7500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We display the google_stock DataFrame\n",
    "all_stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "Before we proceed to get some statistics on the stock data, let's first check that we don't have any *NaN* values. In the space below check if there are any *NaN* values in the `all_stocks`  dataframe. If there are any, remove any rows that have *NaN* values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOOG</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-19</th>\n",
       "      <td>49.845802</td>\n",
       "      <td>1.973460</td>\n",
       "      <td>38.630001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-20</th>\n",
       "      <td>53.805050</td>\n",
       "      <td>1.979244</td>\n",
       "      <td>39.509998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-23</th>\n",
       "      <td>54.346527</td>\n",
       "      <td>1.997236</td>\n",
       "      <td>39.450001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-24</th>\n",
       "      <td>52.096165</td>\n",
       "      <td>2.053144</td>\n",
       "      <td>39.049999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-25</th>\n",
       "      <td>52.657513</td>\n",
       "      <td>2.123831</td>\n",
       "      <td>40.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-26</th>\n",
       "      <td>53.606342</td>\n",
       "      <td>2.227291</td>\n",
       "      <td>40.189999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-27</th>\n",
       "      <td>52.732029</td>\n",
       "      <td>2.207371</td>\n",
       "      <td>39.900002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-30</th>\n",
       "      <td>50.675404</td>\n",
       "      <td>2.192590</td>\n",
       "      <td>38.310001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-31</th>\n",
       "      <td>50.854240</td>\n",
       "      <td>2.216367</td>\n",
       "      <td>38.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-01</th>\n",
       "      <td>49.801090</td>\n",
       "      <td>2.304405</td>\n",
       "      <td>38.240002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-02</th>\n",
       "      <td>50.427021</td>\n",
       "      <td>2.291552</td>\n",
       "      <td>39.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-03</th>\n",
       "      <td>49.681866</td>\n",
       "      <td>2.263920</td>\n",
       "      <td>38.740002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-07</th>\n",
       "      <td>50.461796</td>\n",
       "      <td>2.297979</td>\n",
       "      <td>38.509998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-08</th>\n",
       "      <td>50.819469</td>\n",
       "      <td>2.335893</td>\n",
       "      <td>38.009998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-09</th>\n",
       "      <td>50.824436</td>\n",
       "      <td>2.294122</td>\n",
       "      <td>38.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-10</th>\n",
       "      <td>52.324677</td>\n",
       "      <td>2.305047</td>\n",
       "      <td>38.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-13</th>\n",
       "      <td>53.402668</td>\n",
       "      <td>2.287054</td>\n",
       "      <td>40.009998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-14</th>\n",
       "      <td>55.384777</td>\n",
       "      <td>2.280628</td>\n",
       "      <td>42.669998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-15</th>\n",
       "      <td>55.638126</td>\n",
       "      <td>2.261993</td>\n",
       "      <td>42.209999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-16</th>\n",
       "      <td>56.616764</td>\n",
       "      <td>2.335893</td>\n",
       "      <td>42.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-17</th>\n",
       "      <td>58.365391</td>\n",
       "      <td>2.386659</td>\n",
       "      <td>42.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-20</th>\n",
       "      <td>59.294346</td>\n",
       "      <td>2.423287</td>\n",
       "      <td>43.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-21</th>\n",
       "      <td>58.539257</td>\n",
       "      <td>2.442566</td>\n",
       "      <td>43.290001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-22</th>\n",
       "      <td>58.807514</td>\n",
       "      <td>2.372521</td>\n",
       "      <td>41.380001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-23</th>\n",
       "      <td>60.019630</td>\n",
       "      <td>2.395013</td>\n",
       "      <td>41.830002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-24</th>\n",
       "      <td>59.527828</td>\n",
       "      <td>2.396298</td>\n",
       "      <td>40.939999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-27</th>\n",
       "      <td>58.747902</td>\n",
       "      <td>2.411721</td>\n",
       "      <td>39.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-28</th>\n",
       "      <td>63.020115</td>\n",
       "      <td>2.444494</td>\n",
       "      <td>39.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-29</th>\n",
       "      <td>65.116478</td>\n",
       "      <td>2.485621</td>\n",
       "      <td>40.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-30</th>\n",
       "      <td>64.381264</td>\n",
       "      <td>2.490119</td>\n",
       "      <td>40.860001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-17</th>\n",
       "      <td>771.229980</td>\n",
       "      <td>108.598877</td>\n",
       "      <td>756.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-18</th>\n",
       "      <td>760.539978</td>\n",
       "      <td>108.707527</td>\n",
       "      <td>760.159973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-21</th>\n",
       "      <td>769.200012</td>\n",
       "      <td>110.357010</td>\n",
       "      <td>780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-22</th>\n",
       "      <td>768.270020</td>\n",
       "      <td>110.426147</td>\n",
       "      <td>785.330017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-23</th>\n",
       "      <td>760.989990</td>\n",
       "      <td>109.863159</td>\n",
       "      <td>780.119995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-25</th>\n",
       "      <td>761.679993</td>\n",
       "      <td>110.416275</td>\n",
       "      <td>780.369995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-28</th>\n",
       "      <td>768.239990</td>\n",
       "      <td>110.198975</td>\n",
       "      <td>766.770020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-29</th>\n",
       "      <td>770.840027</td>\n",
       "      <td>110.090332</td>\n",
       "      <td>762.520020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-30</th>\n",
       "      <td>758.039978</td>\n",
       "      <td>109.161880</td>\n",
       "      <td>750.570007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-01</th>\n",
       "      <td>747.919983</td>\n",
       "      <td>108.144531</td>\n",
       "      <td>743.650024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-02</th>\n",
       "      <td>750.500000</td>\n",
       "      <td>108.549500</td>\n",
       "      <td>740.340027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>762.520020</td>\n",
       "      <td>107.769203</td>\n",
       "      <td>759.359985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-06</th>\n",
       "      <td>759.109985</td>\n",
       "      <td>108.598877</td>\n",
       "      <td>764.719971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-07</th>\n",
       "      <td>771.190002</td>\n",
       "      <td>109.665604</td>\n",
       "      <td>770.419983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-08</th>\n",
       "      <td>776.419983</td>\n",
       "      <td>110.742218</td>\n",
       "      <td>767.330017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-09</th>\n",
       "      <td>789.289978</td>\n",
       "      <td>112.549728</td>\n",
       "      <td>768.659973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-12</th>\n",
       "      <td>789.270020</td>\n",
       "      <td>111.907722</td>\n",
       "      <td>760.119995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-13</th>\n",
       "      <td>796.099976</td>\n",
       "      <td>113.774490</td>\n",
       "      <td>774.340027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-14</th>\n",
       "      <td>797.070007</td>\n",
       "      <td>113.774490</td>\n",
       "      <td>768.820007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-15</th>\n",
       "      <td>797.849976</td>\n",
       "      <td>114.396751</td>\n",
       "      <td>761.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-16</th>\n",
       "      <td>790.799988</td>\n",
       "      <td>114.544907</td>\n",
       "      <td>757.770020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>794.200012</td>\n",
       "      <td>115.206673</td>\n",
       "      <td>766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <td>796.419983</td>\n",
       "      <td>115.512863</td>\n",
       "      <td>771.219971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21</th>\n",
       "      <td>794.559998</td>\n",
       "      <td>115.621513</td>\n",
       "      <td>770.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>791.260010</td>\n",
       "      <td>114.860977</td>\n",
       "      <td>766.340027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>789.909973</td>\n",
       "      <td>115.088142</td>\n",
       "      <td>760.590027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>791.549988</td>\n",
       "      <td>115.819054</td>\n",
       "      <td>771.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>785.049988</td>\n",
       "      <td>115.325203</td>\n",
       "      <td>772.130005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>782.789978</td>\n",
       "      <td>115.295570</td>\n",
       "      <td>765.150024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>771.820007</td>\n",
       "      <td>114.396751</td>\n",
       "      <td>749.869995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3115 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GOOG        AAPL        AMZN\n",
       "2004-08-19   49.845802    1.973460   38.630001\n",
       "2004-08-20   53.805050    1.979244   39.509998\n",
       "2004-08-23   54.346527    1.997236   39.450001\n",
       "2004-08-24   52.096165    2.053144   39.049999\n",
       "2004-08-25   52.657513    2.123831   40.299999\n",
       "2004-08-26   53.606342    2.227291   40.189999\n",
       "2004-08-27   52.732029    2.207371   39.900002\n",
       "2004-08-30   50.675404    2.192590   38.310001\n",
       "2004-08-31   50.854240    2.216367   38.139999\n",
       "2004-09-01   49.801090    2.304405   38.240002\n",
       "2004-09-02   50.427021    2.291552   39.180000\n",
       "2004-09-03   49.681866    2.263920   38.740002\n",
       "2004-09-07   50.461796    2.297979   38.509998\n",
       "2004-09-08   50.819469    2.335893   38.009998\n",
       "2004-09-09   50.824436    2.294122   38.070000\n",
       "2004-09-10   52.324677    2.305047   38.570000\n",
       "2004-09-13   53.402668    2.287054   40.009998\n",
       "2004-09-14   55.384777    2.280628   42.669998\n",
       "2004-09-15   55.638126    2.261993   42.209999\n",
       "2004-09-16   56.616764    2.335893   42.570000\n",
       "2004-09-17   58.365391    2.386659   42.959999\n",
       "2004-09-20   59.294346    2.423287   43.270000\n",
       "2004-09-21   58.539257    2.442566   43.290001\n",
       "2004-09-22   58.807514    2.372521   41.380001\n",
       "2004-09-23   60.019630    2.395013   41.830002\n",
       "2004-09-24   59.527828    2.396298   40.939999\n",
       "2004-09-27   58.747902    2.411721   39.930000\n",
       "2004-09-28   63.020115    2.444494   39.430000\n",
       "2004-09-29   65.116478    2.485621   40.840000\n",
       "2004-09-30   64.381264    2.490119   40.860001\n",
       "...                ...         ...         ...\n",
       "2016-11-17  771.229980  108.598877  756.400024\n",
       "2016-11-18  760.539978  108.707527  760.159973\n",
       "2016-11-21  769.200012  110.357010  780.000000\n",
       "2016-11-22  768.270020  110.426147  785.330017\n",
       "2016-11-23  760.989990  109.863159  780.119995\n",
       "2016-11-25  761.679993  110.416275  780.369995\n",
       "2016-11-28  768.239990  110.198975  766.770020\n",
       "2016-11-29  770.840027  110.090332  762.520020\n",
       "2016-11-30  758.039978  109.161880  750.570007\n",
       "2016-12-01  747.919983  108.144531  743.650024\n",
       "2016-12-02  750.500000  108.549500  740.340027\n",
       "2016-12-05  762.520020  107.769203  759.359985\n",
       "2016-12-06  759.109985  108.598877  764.719971\n",
       "2016-12-07  771.190002  109.665604  770.419983\n",
       "2016-12-08  776.419983  110.742218  767.330017\n",
       "2016-12-09  789.289978  112.549728  768.659973\n",
       "2016-12-12  789.270020  111.907722  760.119995\n",
       "2016-12-13  796.099976  113.774490  774.340027\n",
       "2016-12-14  797.070007  113.774490  768.820007\n",
       "2016-12-15  797.849976  114.396751  761.000000\n",
       "2016-12-16  790.799988  114.544907  757.770020\n",
       "2016-12-19  794.200012  115.206673  766.000000\n",
       "2016-12-20  796.419983  115.512863  771.219971\n",
       "2016-12-21  794.559998  115.621513  770.599976\n",
       "2016-12-22  791.260010  114.860977  766.340027\n",
       "2016-12-23  789.909973  115.088142  760.590027\n",
       "2016-12-27  791.549988  115.819054  771.400024\n",
       "2016-12-28  785.049988  115.325203  772.130005\n",
       "2016-12-29  782.789978  115.295570  765.150024\n",
       "2016-12-30  771.820007  114.396751  749.869995\n",
       "\n",
       "[3115 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any NaN values in the all_stocks dataframe\n",
    "all_stocks.isnull().sum().sum()\n",
    "\n",
    "# Remove any rows that contain NaN values\n",
    "all_stocks.dropna(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have eliminated any *NaN* values we can now calculate some basic statistics on the stock prices. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOG    347.420229\n",
      "AAPL     35.222976\n",
      "AMZN    166.095436\n",
      "dtype: float64\n",
      "GOOG    286.397247\n",
      "AAPL     17.524017\n",
      "AMZN     76.980003\n",
      "dtype: float64\n",
      "GOOG    187.671596\n",
      "AAPL     37.945557\n",
      "AMZN    189.212345\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOOG</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900242</td>\n",
       "      <td>0.952444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.900242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.952444</td>\n",
       "      <td>0.906296</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GOOG      AAPL      AMZN\n",
       "GOOG  1.000000  0.900242  0.952444\n",
       "AAPL  0.900242  1.000000  0.906296\n",
       "AMZN  0.952444  0.906296  1.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the average stock price for each stock\n",
    "print(all_stocks.mean(axis=0))\n",
    "\n",
    "# Print the median stock price for each stock\n",
    "print(all_stocks.median(axis=0))\n",
    "\n",
    "# Print the standard deviation of the stock price for each stock  \n",
    "print(all_stocks.std(axis=0))\n",
    "\n",
    "# Print the correlation between stocks\n",
    "all_stocks.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at how we can compute some rolling statistics, also known as moving statistics. We can calculate for example the rolling mean (moving average) of the Google stock price by using the Pandas `dataframe.rolling().mean()` method. The `dataframe.rolling(N).mean()` calculates the rolling mean over an `N`-day window. In other words, we can take a look at the average stock price every `N`  days using the above method. Fill in the code below to calculate the average stock price every 150 days for Google stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the rolling mean using a 150-Day window for Google stock\n",
    "rollingMean = google_stock.rolling(150).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the rolling mean by plotting the data in our dataframe. In the following lessons you will learn how to use **Matplotlib** to visualize data. For now I will just import matplotlib and plot the Google stock data on top of the rolling mean. You can play around by changing the rolling mean window and see how the plot changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Google'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ed5b3b1a1fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# We plot the Google stock data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_stocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Google'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# We plot the rolling mean ontop of our Google stock data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Google'"
     ]
    }
   ],
   "source": [
    "# this allows plots to be rendered in the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# We import matplotlib into Python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# We plot the Google stock data\n",
    "plt.plot(all_stocks['Google'])\n",
    "\n",
    "# We plot the rolling mean ontop of our Google stock data\n",
    "plt.plot(rollingMean)\n",
    "plt.legend(['Google Stock Price', 'Rolling Mean'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
