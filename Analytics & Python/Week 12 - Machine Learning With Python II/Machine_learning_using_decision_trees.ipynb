{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Decision Trees and Machine Learning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Decision trees are tree structures containing rules\n",
    "<li>The leaf nodes of the tree are the \"learned\" categories (or threshold values)\n",
    "<li>A path from the root to a leaf node represents a rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example: A decision tree with rules on deciding who survived or died on the titanic</h3>\n",
    "<i>Source: https://en.wikipedia.org/wiki/Decision_tree_learning#/media/File:CART_tree_titanic_survivors.png</i>\n",
    "<li>To use the tree, enter a person-data object and you'll get an answer</li>\n",
    "<li>Ex: (\"John Brown\",\"Male\",\"30 years old\", \"3 siblings\") Ans: Survived (89% probability)\n",
    "<li>Ex: (\"Jill Jones\", \"Female\",\"7 years old\", \"no siblings\") Ans: Survived (73% probability)\n",
    "<li>Ex: (\"Hercules Mulligan\", \"Male\", \"2 years old\", \"20 siblings\") Ans: Died (17% probability)\n",
    "<li>Note that the 17% probability doesn't mean that there is an 83% chance that Mulligan survived!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = \"CART_tree_titanic_survivors.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Types of decision trees</h2>\n",
    "<ul>\n",
    "<li><b>Classification trees</b>: Uses rules to classify cases into two or more categories (Rocks vs Mines)\n",
    "<ul>\n",
    "<li>Classification trees recursively split the data on a feature value\n",
    "<li>Each split minimizes the cost (also known as the impurity)\n",
    "<li>Cost is commonly measured using the GINI cost function (a measure of the probability of misclassification or 'purity')\n",
    "</ul>\n",
    "<li><b>Regression trees</b>: Uses rules to group data into target variable ranges (Wine Quality)\n",
    "<ul>\n",
    "<li>Also split the data on feature values\n",
    "<li>Minimize cost (impurity). Usually the mean squared error\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Stopping and Pruning Rules</h3>\n",
    "<li>A minimum count of observations in each leaf node\n",
    "<li>A maximum tree <b>depth</b>\n",
    "<li>A maximum <b>complexity</b> (the number of splits)\n",
    "<li>Using all three, you won't necessarily have a balanced tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predicting wine quality using a decision tree</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import the data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "w_df = pd.read_csv(url,header=0,sep=';')\n",
    "w_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Build train and test samples</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(w_df, test_size = 0.3)\n",
    "x_train = train.iloc[0:,0:11]\n",
    "y_train = train[['quality']]\n",
    "x_test = test.iloc[0:,0:11]\n",
    "y_test = test[['quality']]\n",
    "\n",
    "#Use all data for cross validation\n",
    "x_data = w_df.iloc[0:,0:11]\n",
    "y_data = w_df[['quality']]\n",
    "#x_data\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classifiers vs Regressors</h3>\n",
    "<li>Decision tree regressors are used when the target variable is continuous and ordered (wine quality from 0 to 10)\n",
    "<li>Classifiers are used when the target variable is a set of unordered categories (rocks or mines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>For wine quality, we need a regressor</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth = 3)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the R-Square for the predicted vs actuals on the text sample\n",
    "print(\"Training R-Square\",model.score(x_train,y_train))\n",
    "print(\"Testing R-Square\",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>View the tree</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Download and install <a href=\"http://www.graphviz.org/Download.php\">graphviz</a></h3>\n",
    "If you are having issues using Graphviz in Windows, then try the following steps:\n",
    "<ol>\n",
    "<li>1. Install Graphviz \n",
    "<li>2. After installing graphviz, add it to the Computer's Path. \n",
    "<ul>\n",
    "<li>Go to PC properties \n",
    "<li> Click environment variables in the advanced settings section\n",
    "<li> Add C:\\Program Files (x86)\\Graphviz2.38\\bin\\ to the PATH and click Apply\n",
    "</ul>\n",
    "<li> Install Pydotplus. Note that you will always have to install pydot after graphviz as Pydot is Graphviz's dot language and needs Graphviz for reference. \n",
    "</ol>\n",
    "<h3>Install pydotplus (using pip): Install graphviz before you install pydotplus!</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "feature_names = [key for key in w_df]\n",
    "dot_data = tree.export_graphviz(model.tree_, out_file=None,feature_names=feature_names) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "graph.write_pdf(\"wines.pdf\") \n",
    "#The tree will be saved to wines.pdf in your current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision trees are Entropy minimizers</h3>\n",
    "<li><b>Entropy</b>: a measure of uncertainty in the data<p>\n",
    "what is the uncertainty in color when you draw a marble from a box of 100 blue marbles?<p>\n",
    "what is the uncertainty when you draw a marble from a box with 50 blue and 50 red marbles?\n",
    "<li>Entropy minimization: decision tree algorithms seek to partition the data on features in the way that total entropy is minimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression trees</h3>\n",
    "<li>Run regressions for each X to the dependent variable\n",
    "<li>Pick the variable with the most explanatory power and split it at several points\n",
    "<li>Calculate the Mean Square Error of each of the two halves for each split\n",
    "<li>Pick the split point that gives the lowest mse (combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cross validation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Split the training set into k smaller sets (aka folds)\n",
    "<li>Train the data on k-1 folds\n",
    "<li>Validate the results on fold k\n",
    "<li>Repeat this holding out each of the k folds in turn\n",
    "<li>Report the average of all tests as the performance metric\n",
    "<li>http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import cross_val_score\n",
    "#from sklearn.cross_validation import KFold\n",
    "crossvalidation = KFold(n_splits=5,shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "for depth in range(1,10):\n",
    "    model = tree.DecisionTreeRegressor(\n",
    "    max_depth=depth, random_state=0)\n",
    "    if model.fit(x_data,y_data).tree_.max_depth < depth:\n",
    "        break\n",
    "    score = np.mean(cross_val_score(model, x_data, y_data,scoring='neg_mean_squared_error', cv=crossvalidation, n_jobs=1))\n",
    "    print ('Depth: %i Accuracy: %.3f' % (depth,score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Purpose of cross-validation</h3>\n",
    "<li>Not to generate a tree (it generates many trees!)\n",
    "<li>But to provide an estimate of the average error of the model\n",
    "<li>Roughly, the idea is to see how the model performance varies with different training sets\n",
    "<li>To generate the tree, use the entire training set as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classification trees</h1>\n",
    "<h2>Classification trees are used when dealing with categorical dependent variables</h2>\n",
    "<li>Pick a variable and a split point so that the misclassification cost is the lowest.\n",
    "\n",
    "<h3>Rocks and mines data set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "df = pd.read_csv(url,header=None)\n",
    "df[60]=np.where(df[60]=='R',0,1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size = 0.3)\n",
    "x_train = train.iloc[0:,0:60]\n",
    "y_train = train[[60]]\n",
    "x_test = test.iloc[0:,0:60]\n",
    "y_test = test[[60]]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth = 3,criterion='entropy')\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "feature_names = [key for key in df]\n",
    "dot_data = tree.export_graphviz(model.tree_, out_file=None,feature_names=feature_names) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "graph.write_pdf(\"mines.pdf\") \n",
    "#The tree will be saved to mines.pdf in your current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(predicted, actual, threshold):\n",
    "    if len(predicted) != len(actual): return -1\n",
    "    tp = 0.0\n",
    "    fp = 0.0\n",
    "    tn = 0.0\n",
    "    fn = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] > 0.5: #labels that are 1.0  (positive examples)\n",
    "            if predicted[i] > threshold:\n",
    "                tp += 1.0 #correctly predicted positive\n",
    "            else:\n",
    "                fn += 1.0 #incorrectly predicted negative\n",
    "        else:              #labels that are 0.0 (negative examples)\n",
    "            if predicted[i] < threshold:\n",
    "                tn += 1.0 #correctly predicted negative\n",
    "            else:\n",
    "                fp += 1.0 #incorrectly predicted positive\n",
    "    rtn = [tp, fn, fp, tn]\n",
    "\n",
    "    return rtn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_train=model.predict(x_train)\n",
    "p_test = model.predict(x_test)\n",
    "print(confusion_matrix(p_train,np.array(y_train),.5))\n",
    "print(confusion_matrix(p_test,np.array(y_test),.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "import pylab as pl\n",
    "%matplotlib inline\n",
    "(fpr, tpr, thresholds) = roc_curve(y_train,p_train)\n",
    "area = auc(fpr,tpr)\n",
    "pl.clf() #Clear the current figure\n",
    "pl.plot(fpr,tpr,label=\"In-Sample ROC Curve with area = %1.2f\"%area)\n",
    "\n",
    "pl.plot([0, 1], [0, 1], 'k') #This plots the random (equal probability line)\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.ylim([0.0, 1.0])\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('In sample ROC rocks versus mines')\n",
    "pl.legend(loc=\"lower right\")\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr,tpr,thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "import pylab as pl\n",
    "%matplotlib inline\n",
    "(fpr, tpr, thresholds) = roc_curve(y_test,p_test)\n",
    "area = auc(fpr,tpr)\n",
    "pl.clf() #Clear the current figure\n",
    "pl.plot(fpr,tpr,label=\"Out-Sample ROC Curve with area = %1.2f\"%area)\n",
    "\n",
    "pl.plot([0, 1], [0, 1], 'k') #This plots the random (equal probability line)\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.ylim([0.0, 1.0])\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('Out sample ROC rocks versus mines')\n",
    "pl.legend(loc=\"lower right\")\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
